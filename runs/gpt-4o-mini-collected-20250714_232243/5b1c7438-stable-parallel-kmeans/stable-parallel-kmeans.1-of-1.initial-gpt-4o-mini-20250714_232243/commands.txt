['asciinema rec --stdin /logs/agent.cast', 'Enter']
['clear', 'Enter']
'echo "import numpy as np\\nfrom sklearn.cluster import KMeans\\nimport multiprocessing\\n\\nclass StableKMeans:\\n    def __init__(self, data, k_max, percent_subsampling=0.7, number_of_subsamples=20):\\n        self.data = data\\n        self.k_max = k_max\\n        self.percent_subsampling = percent_subsampling\\n        self.number_of_subsamples = number_of_subsamples\\n        self.stability_scores = []\\n        self.optimal_k = None\\n\\n    def fit_serial(self, verbose=True):\\n        for k in range(1, self.k_max + 1):\\n            scores = []\\n            for _ in range(self.number_of_subsamples):\\n                subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\\n                kmeans = KMeans(n_clusters=k).fit(subsample)\\n                scores.append(kmeans.inertia_)\\n            stability = np.std(scores)\\n            self.stability_scores.append(stability)\\n            if verbose:\\n                print(f\'K: {k}, Stability: {stability}\')\\n        self.optimal_k = np.argmin(self.stability_scores) + 1\\n\\n    def fit_parallel(self, n_jobs=None, verbose=True):\\n        with multiprocessing.Pool(n_jobs) as pool:\\n            results = pool.map(self._kmeans_subsample, range(1, self.k_max + 1))\\n        self.stability_scores = [result[0] for result in results]\\n        self.optimal_k = np.argmin(self.stability_scores) + 1\\n        if verbose:\\n            for k, stability in enumerate(self.stability_scores, start=1):\\n                print(f\'K: {k}, Stability: {stability}\')\\n\\n    def _kmeans_subsample(self, k):\\n        scores = []\\n        for _ in range(self.number_of_subsamples):\\n            subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\\n            kmeans = KMeans(n_clusters=k).fit(subsample)\\n            scores.append(kmeans.inertia_)\\n        stability = np.std(scores)\\n        return stability, k\\n\\n    def get_optimal_k(self):\\n        return self.optimal_k\\n\\n    def get_stability_summary(self):\\n        return self.stability_scores" > stable_kmeans.py\n'
'echo "import numpy as np\\nfrom stable_kmeans import StableKMeans\\nfrom sklearn.datasets import make_blobs\\nimport time\\n\\n# Generate data\\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\\n\\n# Initialize\\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\\n\\n# Run serial\\nstart_time = time.time()\\nsk.fit_serial(verbose=True)\\nserial_time = time.time() - start_time\\noptimal_k = sk.get_optimal_k()\\n\\n# Run parallel\\nstart_time = time.time()\\nsk.fit_parallel(n_jobs=2, verbose=True)\\nparallel_time = time.time() - start_time\\nspeedup = serial_time / parallel_time\\n\\n# Compare performance\\nprint(f\'Serial time: {serial_time:.4f} seconds\')\\nprint(f\'Parallel time: {parallel_time:.4f} seconds\')\\nprint(f\'Speedup: {speedup:.2f}x\')\\nprint(f\'Optimal k: {optimal_k}\')" > test_implementation.py\n'
'python3 test_implementation.py\n'
'echo "import numpy as np\\nfrom stable_kmeans import StableKMeans\\nfrom sklearn.datasets import make_blobs\\nimport time\\n\\n# Generate data\\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\\n\\n# Initialize\\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\\n\\n# Run serial\\nstart_time = time.time()\\nsk.fit_serial(verbose=True)\\nserial_time = time.time() - start_time\\noptimal_k = sk.get_optimal_k()\\n\\n# Run parallel\\nstart_time = time.time()\\nsk.fit_parallel(n_jobs=2, verbose=True)\\nparallel_time = time.time() - start_time\\nspeedup = serial_time / parallel_time\\n\\n# Compare performance\\nprint(f\'Serial time: {serial_time:.4f} seconds\')\\nprint(f\'Parallel time: {parallel_time:.4f} seconds\')\\nprint(f\'Speedup: {speedup:.2f}x\')\\nprint(f\'Optimal k: {optimal_k}\')" > test_implementation.py\n'
'echo "import numpy as np\\nfrom stable_kmeans import StableKMeans\\nfrom sklearn.datasets import make_blobs\\nimport time\\n\\n# Generate data\\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\\n\\n# Initialize\\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\\n\\n# Run serial\\nstart_time = time.time()\\nsk.fit_serial(verbose=True)\\nserial_time = time.time() - start_time\\noptimal_k = sk.get_optimal_k()\\n\\n# Run parallel\\nstart_time = time.time()\\nsk.fit_parallel(n_jobs=2, verbose=True)\\nparallel_time = time.time() - start_time\\nspeedup = serial_time / parallel_time\\n\\n# Compare performance\\nprint(f\'Serial time: {serial_time:.4f} seconds\')\\nprint(f\'Parallel time: {parallel_time:.4f} seconds\')\\nprint(f\'Speedup: {speedup:.2f}x\')\\nprint(f\'Optimal k: {optimal_k}\')" > test_implementation.py\n'
'echo "import numpy as np\\nfrom stable_kmeans import StableKMeans\\nfrom sklearn.datasets import make_blobs\\nimport time\\n\\n# Generate data\\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\\n\\n# Initialize\\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\\n\\n# Run serial\\nstart_time = time.time()\\nsk.fit_serial(verbose=True)\\nserial_time = time.time() - start_time\\noptimal_k = sk.get_optimal_k()\\n\\n# Run parallel\\nstart_time = time.time()\\nsk.fit_parallel(n_jobs=2, verbose=True)\\nparallel_time = time.time() - start_time\\nspeedup = serial_time / parallel_time\\n\\n# Compare performance\\nprint(f\'Serial time: {serial_time:.4f} seconds\')\\nprint(f\'Parallel time: {parallel_time:.4f} seconds\')\\nprint(f\'Speedup: {speedup:.2f}x\')\\nprint(f\'Optimal k: {optimal_k}\')" > test_implementation.py\n'
'echo "import numpy as np\\nfrom stable_kmeans import StableKMeans\\nfrom sklearn.datasets import make_blobs\\nimport time\\n\\n# Generate data\\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\\n\\n# Initialize\\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\\n\\n# Run serial\\nstart_time = time.time()\\nsk.fit_serial(verbose=True)\\nserial_time = time.time() - start_time\\noptimal_k = sk.get_optimal_k()\\n\\n# Run parallel\\nstart_time = time.time()\\nsk.fit_parallel(n_jobs=2, verbose=True)\\nparallel_time = time.time() - start_time\\nspeedup = serial_time / parallel_time\\n\\n# Compare performance\\nprint(f\'Serial time: {serial_time:.4f} seconds\')\\nprint(f\'Parallel time: {parallel_time:.4f} seconds\')\\nprint(f\'Speedup: {speedup:.2f}x\')\\nprint(f\'Optimal k: {optimal_k}\')" > test_implementation.py\n'
'echo "import numpy as np\\nfrom stable_kmeans import StableKMeans\\nfrom sklearn.datasets import make_blobs\\nimport time\\n\\n# Generate data\\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\\n\\n# Initialize\\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\\n\\n# Run serial\\nstart_time = time.time()\\nsk.fit_serial(verbose=True)\\nserial_time = time.time() - start_time\\noptimal_k = sk.get_optimal_k()\\n\\n# Run parallel\\nstart_time = time.time()\\nsk.fit_parallel(n_jobs=2, verbose=True)\\nparallel_time = time.time() - start_time\\nspeedup = serial_time / parallel_time\\n\\n# Compare performance\\nprint(f\'Serial time: {serial_time:.4f} seconds\')\\nprint(f\'Parallel time: {parallel_time:.4f} seconds\')\\nprint(f\'Speedup: {speedup:.2f}x\')\\nprint(f\'Optimal k: {optimal_k}\')" > test_implementation.py\n'
'echo "import numpy as np\\nfrom stable_kmeans import StableKMeans\\nfrom sklearn.datasets import make_blobs\\nimport time\\n\\n# Generate data\\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\\n\\n# Initialize\\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\\n\\n# Run serial\\nstart_time = time.time()\\nsk.fit_serial(verbose=True)\\nserial_time = time.time() - start_time\\noptimal_k = sk.get_optimal_k()\\n\\n# Run parallel\\nstart_time = time.time()\\nsk.fit_parallel(n_jobs=2, verbose=True)\\nparallel_time = time.time() - start_time\\nspeedup = serial_time / parallel_time\\n\\n# Compare performance\\nprint(f\'Serial time: {serial_time:.4f} seconds\')\\nprint(f\'Parallel time: {parallel_time:.4f} seconds\')\\nprint(f\'Speedup: {speedup:.2f}x\')\\nprint(f\'Optimal k: {optimal_k}\')" > test_implementation.py\n'
'echo "import numpy as np\\nfrom stable_kmeans import StableKMeans\\nfrom sklearn.datasets import make_blobs\\nimport time\\n\\n# Generate data\\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\\n\\n# Initialize\\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\\n\\n# Run serial\\nstart_time = time.time()\\nsk.fit_serial(verbose=True)\\nserial_time = time.time() - start_time\\noptimal_k = sk.get_optimal_k()\\n\\n# Run parallel\\nstart_time = time.time()\\nsk.fit_parallel(n_jobs=2, verbose=True)\\nparallel_time = time.time() - start_time\\nspeedup = serial_time / parallel_time\\n\\n# Compare performance\\nprint(f\'Serial time: {serial_time:.4f} seconds\')\\nprint(f\'Parallel time: {parallel_time:.4f} seconds\')\\nprint(f\'Speedup: {speedup:.2f}x\')\\nprint(f\'Optimal k: {optimal_k}\')" > test_implementation.py\n'
'echo "import numpy as np\\nfrom stable_kmeans import StableKMeans\\nfrom sklearn.datasets import make_blobs\\nimport time\\n\\n# Generate data\\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\\n\\n# Initialize\\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\\n\\n# Run serial\\nstart_time = time.time()\\nsk.fit_serial(verbose=True)\\nserial_time = time.time() - start_time\\noptimal_k = sk.get_optimal_k()\\n\\n# Run parallel\\nstart_time = time.time()\\nsk.fit_parallel(n_jobs=2, verbose=True)\\nparallel_time = time.time() - start_time\\nspeedup = serial_time / parallel_time\\n\\n# Compare performance\\nprint(f\'Serial time: {serial_time:.4f} seconds\')\\nprint(f\'Parallel time: {parallel_time:.4f} seconds\')\\nprint(f\'Speedup: {speedup:.2f}x\')\\nprint(f\'Optimal k: {optimal_k}\')" > test_implementation.py\n'
"cat <<EOF > test_implementation.py\nimport numpy as np\nfrom stable_kmeans import StableKMeans\nfrom sklearn.datasets import make_blobs\nimport time\n\n# Generate data\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\n\n# Initialize\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\n\n# Run serial\nstart_time = time.time()\nsk.fit_serial(verbose=True)\nserial_time = time.time() - start_time\noptimal_k = sk.get_optimal_k()\n\n# Run parallel\nstart_time = time.time()\nsk.fit_parallel(n_jobs=2, verbose=True)\nparallel_time = time.time() - start_time\nspeedup = serial_time / parallel_time\n\n# Compare performance\nprint(f'Serial time: {serial_time:.4f} seconds')\nprint(f'Parallel time: {parallel_time:.4f} seconds')\nprint(f'Speedup: {speedup:.2f}x')\nprint(f'Optimal k: {optimal_k}')\nEOF\n"
'python3 test_implementation.py\n'
"cat <<EOF > stable_kmeans.py\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport multiprocessing\n\nclass StableKMeans:\n    def __init__(self, data, k_max, percent_subsampling=0.7, number_of_subsamples=20):\n        self.data = data\n        self.k_max = k_max\n        self.percent_subsampling = percent_subsampling\n        self.number_of_subsamples = number_of_subsamples\n        self.stability_scores = []\n        self.optimal_k = None\n\n    def fit_serial(self, verbose=True):\n        for k in range(1, self.k_max + 1):\n            scores = []\n            for _ in range(self.number_of_subsamples):\n                subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n                kmeans = KMeans(n_clusters=k).fit(subsample)\n                scores.append(kmeans.inertia_)\n            stability = np.std(scores)\n            self.stability_scores.append(stability)\n            if verbose:\n                print(f'K: {k}, Stability: {stability}')\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n\n    def fit_parallel(self, n_jobs=None, verbose=True):\n        with multiprocessing.Pool(n_jobs) as pool:\n            results = pool.map(self._kmeans_subsample, range(1, self.k_max + 1))\n        self.stability_scores = [result[0] for result in results]\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n        if verbose:\n            for k, stability in enumerate(self.stability_scores, start=1):\n                print(f'K: {k}, Stability: {stability}')\n\n    def _kmeans_subsample(self, k):\n        scores = []\n        for _ in range(self.number_of_subsamples):\n            subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n            kmeans = KMeans(n_clusters=k).fit(subsample)\n            scores.append(kmeans.inertia_)\n        stability = np.std(scores)\n        return stability, k\n\n    def get_optimal_k(self):\n        return self.optimal_k\n\n    def get_stability_summary(self):\n        return self.stability_scores\nEOF\n"
'python3 test_implementation.py\n'
'# Check the output for optimal k and performance times\n'
"optimal_k = sk.get_optimal_k()\nprint(f'Optimal k: {optimal_k}')\n"
"optimal_k = sk.get_optimal_k()\nprint(f'Optimal k: {optimal_k}')\n"
"print(f'Stability Scores: {sk.get_stability_summary()}')\nprint(f'Optimal k: {sk.get_optimal_k()}')\n"
'print(sk.get_stability_summary())\nprint(sk.get_optimal_k())\n'
'python3 test_implementation.py\n'
"# Directly check the values in the interpreter\noptimal_k = sk.get_optimal_k()\nstability_scores = sk.get_stability_summary()\nprint(f'Optimal k: {optimal_k}')\nprint(f'Stability Scores: {stability_scores}')\n"
'# Restarting the terminal session to clear any hanging processes\n\n'
"optimal_k = sk.get_optimal_k()\nstability_scores = sk.get_stability_summary()\nprint(f'Optimal k: {optimal_k}')\nprint(f'Stability Scores: {stability_scores}')\n"
'python3\n'
'# Restart the Docker container to reset the environment\n'
'# Exit the current shell and restart the Docker container\nexit\n'
'# Recreate the stable_kmeans.py and test_implementation.py files after restart\n'
"cat <<EOF > stable_kmeans.py\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport multiprocessing\n\nclass StableKMeans:\n    def __init__(self, data, k_max, percent_subsampling=0.7, number_of_subsamples=20):\n        self.data = data\n        self.k_max = k_max\n        self.percent_subsampling = percent_subsampling\n        self.number_of_subsamples = number_of_subsamples\n        self.stability_scores = []\n        self.optimal_k = None\n\n    def fit_serial(self, verbose=True):\n        for k in range(1, self.k_max + 1):\n            scores = []\n            for _ in range(self.number_of_subsamples):\n                subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n                kmeans = KMeans(n_clusters=k).fit(subsample)\n                scores.append(kmeans.inertia_)\n            stability = np.std(scores)\n            self.stability_scores.append(stability)\n            if verbose:\n                print(f'K: {k}, Stability: {stability}')\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n\n    def fit_parallel(self, n_jobs=None, verbose=True):\n        with multiprocessing.Pool(n_jobs) as pool:\n            results = pool.map(self._kmeans_subsample, range(1, self.k_max + 1))\n        self.stability_scores = [result[0] for result in results]\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n        if verbose:\n            for k, stability in enumerate(self.stability_scores, start=1):\n                print(f'K: {k}, Stability: {stability}')\n\n    def _kmeans_subsample(self, k):\n        scores = []\n        for _ in range(self.number_of_subsamples):\n            subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n            kmeans = KMeans(n_clusters=k).fit(subsample)\n            scores.append(kmeans.inertia_)\n        stability = np.std(scores)\n        return stability, k\n\n    def get_optimal_k(self):\n        return self.optimal_k\n\n    def get_stability_summary(self):\n        return self.stability_scores\nEOF\n"
"cat <<EOF > test_implementation.py\nimport numpy as np\nfrom stable_kmeans import StableKMeans\nfrom sklearn.datasets import make_blobs\nimport time\n\n# Generate data\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\n\n# Initialize\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\n\n# Run serial\nstart_time = time.time()\nsk.fit_serial(verbose=True)\nserial_time = time.time() - start_time\noptimal_k = sk.get_optimal_k()\n\n# Run parallel\nstart_time = time.time()\nsk.fit_parallel(n_jobs=2, verbose=True)\nparallel_time = time.time() - start_time\nspeedup = serial_time / parallel_time\n\n# Compare performance\nprint(f'Serial time: {serial_time:.4f} seconds')\nprint(f'Parallel time: {parallel_time:.4f} seconds')\nprint(f'Speedup: {speedup:.2f}x')\nprint(f'Optimal k: {optimal_k}')\nEOF\n"
'python3 test_implementation.py\n'
'python3\n'
'# Stop and restart the Docker container to reset the environment\n'
'python3 test_implementation.py\n'
'python3\n'
'# Restart the Docker container to reset the environment fully\n'
'python3\n'
'# Stop and restart the Docker container to reset the environment\n'
'# Restart the Docker container to reset the environment fully\n'
"cat <<EOF > stable_kmeans.py\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport multiprocessing\n\nclass StableKMeans:\n    def __init__(self, data, k_max, percent_subsampling=0.7, number_of_subsamples=20):\n        self.data = data\n        self.k_max = k_max\n        self.percent_subsampling = percent_subsampling\n        self.number_of_subsamples = number_of_subsamples\n        self.stability_scores = []\n        self.optimal_k = None\n\n    def fit_serial(self, verbose=True):\n        for k in range(1, self.k_max + 1):\n            scores = []\n            for _ in range(self.number_of_subsamples):\n                subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n                kmeans = KMeans(n_clusters=k).fit(subsample)\n                scores.append(kmeans.inertia_)\n            stability = np.std(scores)\n            self.stability_scores.append(stability)\n            if verbose:\n                print(f'K: {k}, Stability: {stability}')\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n\n    def fit_parallel(self, n_jobs=None, verbose=True):\n        with multiprocessing.Pool(n_jobs) as pool:\n            results = pool.map(self._kmeans_subsample, range(1, self.k_max + 1))\n        self.stability_scores = [result[0] for result in results]\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n        if verbose:\n            for k, stability in enumerate(self.stability_scores, start=1):\n                print(f'K: {k}, Stability: {stability}')\n\n    def _kmeans_subsample(self, k):\n        scores = []\n        for _ in range(self.number_of_subsamples):\n            subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n            kmeans = KMeans(n_clusters=k).fit(subsample)\n            scores.append(kmeans.inertia_)\n        stability = np.std(scores)\n        return stability, k\n\n    def get_optimal_k(self):\n        return self.optimal_k\n\n    def get_stability_summary(self):\n        return self.stability_scores\nEOF\n\ncat <<EOF > test_implementation.py\nimport numpy as np\nfrom stable_kmeans import StableKMeans\nfrom sklearn.datasets import make_blobs\nimport time\n\n# Generate data\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\n\n# Initialize\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\n\n# Run serial\nstart_time = time.time()\nsk.fit_serial(verbose=True)\nserial_time = time.time() - start_time\noptimal_k = sk.get_optimal_k()\n\n# Run parallel\nstart_time = time.time()\nsk.fit_parallel(n_jobs=2, verbose=True)\nparallel_time = time.time() - start_time\nspeedup = serial_time / parallel_time\n\n# Compare performance\nprint(f'Serial time: {serial_time:.4f} seconds')\nprint(f'Parallel time: {parallel_time:.4f} seconds')\nprint(f'Speedup: {speedup:.2f}x')\nprint(f'Optimal k: {optimal_k}')\nEOF\n\npython3 test_implementation.py\n"
"cat <<EOF > stable_kmeans.py\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport multiprocessing\n\nclass StableKMeans:\n    def __init__(self, data, k_max, percent_subsampling=0.7, number_of_subsamples=20):\n        self.data = data\n        self.k_max = k_max\n        self.percent_subsampling = percent_subsampling\n        self.number_of_subsamples = number_of_subsamples\n        self.stability_scores = []\n        self.optimal_k = None\n\n    def fit_serial(self, verbose=True):\n        for k in range(1, self.k_max + 1):\n            scores = []\n            for _ in range(self.number_of_subsamples):\n                subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n                kmeans = KMeans(n_clusters=k).fit(subsample)\n                scores.append(kmeans.inertia_)\n            stability = np.std(scores)\n            self.stability_scores.append(stability)\n            if verbose:\n                print(f'K: {k}, Stability: {stability}')\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n\n    def fit_parallel(self, n_jobs=None, verbose=True):\n        with multiprocessing.Pool(n_jobs) as pool:\n            results = pool.map(self._kmeans_subsample, range(1, self.k_max + 1))\n        self.stability_scores = [result[0] for result in results]\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n        if verbose:\n            for k, stability in enumerate(self.stability_scores, start=1):\n                print(f'K: {k}, Stability: {stability}')\n\n    def _kmeans_subsample(self, k):\n        scores = []\n        for _ in range(self.number_of_subsamples):\n            subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n            kmeans = KMeans(n_clusters=k).fit(subsample)\n            scores.append(kmeans.inertia_)\n        stability = np.std(scores)\n        return stability, k\n\n    def get_optimal_k(self):\n        return self.optimal_k\n\n    def get_stability_summary(self):\n        return self.stability_scores\nEOF\n\ncat <<EOF > test_implementation.py\nimport numpy as np\nfrom stable_kmeans import StableKMeans\nfrom sklearn.datasets import make_blobs\nimport time\n\n# Generate data\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\n\n# Initialize\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\n\n# Run serial\nstart_time = time.time()\nsk.fit_serial(verbose=True)\nserial_time = time.time() - start_time\noptimal_k = sk.get_optimal_k()\n\n# Run parallel\nstart_time = time.time()\nsk.fit_parallel(n_jobs=2, verbose=True)\nparallel_time = time.time() - start_time\nspeedup = serial_time / parallel_time\n\n# Compare performance\nprint(f'Serial time: {serial_time:.4f} seconds')\nprint(f'Parallel time: {parallel_time:.4f} seconds')\nprint(f'Speedup: {speedup:.2f}x')\nprint(f'Optimal k: {optimal_k}')\nEOF\n\npython3 test_implementation.py\n"
'# Check system resources and memory usage to diagnose issues\nfree -h\n'
'# Reset the Docker container environment to clear any hanging processes\n'
"cat <<EOF > minimal_test.py\nimport numpy as np\\nprint('Testing minimal script execution...')\\nEOF\n"
'python3 minimal_test.py\n'
'# Restart the Docker container to reset the environment completely\n'
"cat <<EOF > stable_kmeans.py\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport multiprocessing\n\nclass StableKMeans:\n    def __init__(self, data, k_max, percent_subsampling=0.7, number_of_subsamples=20):\n        self.data = data\n        self.k_max = k_max\n        self.percent_subsampling = percent_subsampling\n        self.number_of_subsamples = number_of_subsamples\n        self.stability_scores = []\n        self.optimal_k = None\n\n    def fit_serial(self, verbose=True):\n        for k in range(1, self.k_max + 1):\n            scores = []\n            for _ in range(self.number_of_subsamples):\n                subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n                kmeans = KMeans(n_clusters=k).fit(subsample)\n                scores.append(kmeans.inertia_)\n            stability = np.std(scores)\n            self.stability_scores.append(stability)\n            if verbose:\n                print(f'K: {k}, Stability: {stability}')\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n\n    def fit_parallel(self, n_jobs=None, verbose=True):\n        with multiprocessing.Pool(n_jobs) as pool:\n            results = pool.map(self._kmeans_subsample, range(1, self.k_max + 1))\n        self.stability_scores = [result[0] for result in results]\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n        if verbose:\n            for k, stability in enumerate(self.stability_scores, start=1):\n                print(f'K: {k}, Stability: {stability}')\n\n    def _kmeans_subsample(self, k):\n        scores = []\n        for _ in range(self.number_of_subsamples):\n            subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n            kmeans = KMeans(n_clusters=k).fit(subsample)\n            scores.append(kmeans.inertia_)\n        stability = np.std(scores)\n        return stability, k\n\n    def get_optimal_k(self):\n        return self.optimal_k\n\n    def get_stability_summary(self):\n        return self.stability_scores\nEOF\n\ncat <<EOF > test_implementation.py\nimport numpy as np\nfrom stable_kmeans import StableKMeans\nfrom sklearn.datasets import make_blobs\nimport time\n\n# Generate data\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\n\n# Initialize\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\n\n# Run serial\nstart_time = time.time()\nsk.fit_serial(verbose=True)\nserial_time = time.time() - start_time\noptimal_k = sk.get_optimal_k()\n\n# Run parallel\nstart_time = time.time()\nsk.fit_parallel(n_jobs=2, verbose=True)\nparallel_time = time.time() - start_time\nspeedup = serial_time / parallel_time\n\n# Compare performance\nprint(f'Serial time: {serial_time:.4f} seconds')\nprint(f'Parallel time: {parallel_time:.4f} seconds')\nprint(f'Speedup: {speedup:.2f}x')\nprint(f'Optimal k: {optimal_k}')\nEOF\n\npython3 test_implementation.py\n"
"cat <<EOF > stable_kmeans.py\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport multiprocessing\n\nclass StableKMeans:\n    def __init__(self, data, k_max, percent_subsampling=0.7, number_of_subsamples=20):\n        self.data = data\n        self.k_max = k_max\n        self.percent_subsampling = percent_subsampling\n        self.number_of_subsamples = number_of_subsamples\n        self.stability_scores = []\n        self.optimal_k = None\n\n    def fit_serial(self, verbose=True):\n        for k in range(1, self.k_max + 1):\n            scores = []\n            for _ in range(self.number_of_subsamples):\n                subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n                kmeans = KMeans(n_clusters=k).fit(subsample)\n                scores.append(kmeans.inertia_)\n            stability = np.std(scores)\n            self.stability_scores.append(stability)\n            if verbose:\n                print(f'K: {k}, Stability: {stability}')\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n\n    def fit_parallel(self, n_jobs=None, verbose=True):\n        with multiprocessing.Pool(n_jobs) as pool:\n            results = pool.map(self._kmeans_subsample, range(1, self.k_max + 1))\n        self.stability_scores = [result[0] for result in results]\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n        if verbose:\n            for k, stability in enumerate(self.stability_scores, start=1):\n                print(f'K: {k}, Stability: {stability}')\n\n    def _kmeans_subsample(self, k):\n        scores = []\n        for _ in range(self.number_of_subsamples):\n            subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n            kmeans = KMeans(n_clusters=k).fit(subsample)\n            scores.append(kmeans.inertia_)\n        stability = np.std(scores)\n        return stability, k\n\n    def get_optimal_k(self):\n        return self.optimal_k\n\n    def get_stability_summary(self):\n        return self.stability_scores\nEOF\n\ncat <<EOF > test_implementation.py\nimport numpy as np\nfrom stable_kmeans import StableKMeans\nfrom sklearn.datasets import make_blobs\nimport time\n\n# Generate data\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\n\n# Initialize\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\n\n# Run serial\nstart_time = time.time()\nsk.fit_serial(verbose=True)\nserial_time = time.time() - start_time\noptimal_k = sk.get_optimal_k()\n\n# Run parallel\nstart_time = time.time()\nsk.fit_parallel(n_jobs=2, verbose=True)\nparallel_time = time.time() - start_time\nspeedup = serial_time / parallel_time\n\n# Compare performance\nprint(f'Serial time: {serial_time:.4f} seconds')\nprint(f'Parallel time: {parallel_time:.4f} seconds')\nprint(f'Speedup: {speedup:.2f}x')\nprint(f'Optimal k: {optimal_k}')\nEOF\n\npython3 test_implementation.py\n"
"cat <<EOF > stable_kmeans.py\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport multiprocessing\n\nclass StableKMeans:\n    def __init__(self, data, k_max, percent_subsampling=0.7, number_of_subsamples=20):\n        self.data = data\n        self.k_max = k_max\n        self.percent_subsampling = percent_subsampling\n        self.number_of_subsamples = number_of_subsamples\n        self.stability_scores = []\n        self.optimal_k = None\n\n    def fit_serial(self, verbose=True):\n        for k in range(1, self.k_max + 1):\n            scores = []\n            for _ in range(self.number_of_subsamples):\n                subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n                kmeans = KMeans(n_clusters=k).fit(subsample)\n                scores.append(kmeans.inertia_)\n            stability = np.std(scores)\n            self.stability_scores.append(stability)\n            if verbose:\n                print(f'K: {k}, Stability: {stability}')\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n\n    def fit_parallel(self, n_jobs=None, verbose=True):\n        with multiprocessing.Pool(n_jobs) as pool:\n            results = pool.map(self._kmeans_subsample, range(1, self.k_max + 1))\n        self.stability_scores = [result[0] for result in results]\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n        if verbose:\n            for k, stability in enumerate(self.stability_scores, start=1):\n                print(f'K: {k}, Stability: {stability}')\n\n    def _kmeans_subsample(self, k):\n        scores = []\n        for _ in range(self.number_of_subsamples):\n            subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n            kmeans = KMeans(n_clusters=k).fit(subsample)\n            scores.append(kmeans.inertia_)\n        stability = np.std(scores)\n        return stability, k\n\n    def get_optimal_k(self):\n        return self.optimal_k\n\n    def get_stability_summary(self):\n        return self.stability_scores\nEOF\n\ncat <<EOF > test_implementation.py\nimport numpy as np\nfrom stable_kmeans import StableKMeans\nfrom sklearn.datasets import make_blobs\nimport time\n\n# Generate data\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\n\n# Initialize\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\n\n# Run serial\nstart_time = time.time()\nsk.fit_serial(verbose=True)\nserial_time = time.time() - start_time\noptimal_k = sk.get_optimal_k()\n\n# Run parallel\nstart_time = time.time()\nsk.fit_parallel(n_jobs=2, verbose=True)\nparallel_time = time.time() - start_time\nspeedup = serial_time / parallel_time\n\n# Compare performance\nprint(f'Serial time: {serial_time:.4f} seconds')\nprint(f'Parallel time: {parallel_time:.4f} seconds')\nprint(f'Speedup: {speedup:.2f}x')\nprint(f'Optimal k: {optimal_k}')\nEOF\n\npython3 test_implementation.py\n"
'# Completely reset the Docker container environment\n'
"cat <<EOF > stable_kmeans.py\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport multiprocessing\n\nclass StableKMeans:\n    def __init__(self, data, k_max, percent_subsampling=0.7, number_of_subsamples=20):\n        self.data = data\n        self.k_max = k_max\n        self.percent_subsampling = percent_subsampling\n        self.number_of_subsamples = number_of_subsamples\n        self.stability_scores = []\n        self.optimal_k = None\n\n    def fit_serial(self, verbose=True):\n        for k in range(1, self.k_max + 1):\n            scores = []\n            for _ in range(self.number_of_subsamples):\n                subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n                kmeans = KMeans(n_clusters=k).fit(subsample)\n                scores.append(kmeans.inertia_)\n            stability = np.std(scores)\n            self.stability_scores.append(stability)\n            if verbose:\n                print(f'K: {k}, Stability: {stability}')\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n\n    def fit_parallel(self, n_jobs=None, verbose=True):\n        with multiprocessing.Pool(n_jobs) as pool:\n            results = pool.map(self._kmeans_subsample, range(1, self.k_max + 1))\n        self.stability_scores = [result[0] for result in results]\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n        if verbose:\n            for k, stability in enumerate(self.stability_scores, start=1):\n                print(f'K: {k}, Stability: {stability}')\n\n    def _kmeans_subsample(self, k):\n        scores = []\n        for _ in range(self.number_of_subsamples):\n            subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n            kmeans = KMeans(n_clusters=k).fit(subsample)\n            scores.append(kmeans.inertia_)\n        stability = np.std(scores)\n        return stability, k\n\n    def get_optimal_k(self):\n        return self.optimal_k\n\n    def get_stability_summary(self):\n        return self.stability_scores\nEOF\n\ncat <<EOF > test_implementation.py\nimport numpy as np\nfrom stable_kmeans import StableKMeans\nfrom sklearn.datasets import make_blobs\nimport time\n\n# Generate data\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\n\n# Initialize\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\n\n# Run serial\nstart_time = time.time()\nsk.fit_serial(verbose=True)\nserial_time = time.time() - start_time\noptimal_k = sk.get_optimal_k()\n\n# Run parallel\nstart_time = time.time()\nsk.fit_parallel(n_jobs=2, verbose=True)\nparallel_time = time.time() - start_time\nspeedup = serial_time / parallel_time\n\n# Compare performance\nprint(f'Serial time: {serial_time:.4f} seconds')\nprint(f'Parallel time: {parallel_time:.4f} seconds')\nprint(f'Speedup: {speedup:.2f}x')\nprint(f'Optimal k: {optimal_k}')\nEOF\n\npython3 test_implementation.py\n"
"cat <<EOF > stable_kmeans.py\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport multiprocessing\n\nclass StableKMeans:\n    def __init__(self, data, k_max, percent_subsampling=0.7, number_of_subsamples=20):\n        self.data = data\n        self.k_max = k_max\n        self.percent_subsampling = percent_subsampling\n        self.number_of_subsamples = number_of_subsamples\n        self.stability_scores = []\n        self.optimal_k = None\n\n    def fit_serial(self, verbose=True):\n        for k in range(1, self.k_max + 1):\n            scores = []\n            for _ in range(self.number_of_subsamples):\n                subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n                kmeans = KMeans(n_clusters=k).fit(subsample)\n                scores.append(kmeans.inertia_)\n            stability = np.std(scores)\n            self.stability_scores.append(stability)\n            if verbose:\n                print(f'K: {k}, Stability: {stability}')\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n\n    def fit_parallel(self, n_jobs=None, verbose=True):\n        with multiprocessing.Pool(n_jobs) as pool:\n            results = pool.map(self._kmeans_subsample, range(1, self.k_max + 1))\n        self.stability_scores = [result[0] for result in results]\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n        if verbose:\n            for k, stability in enumerate(self.stability_scores, start=1):\n                print(f'K: {k}, Stability: {stability}')\n\n    def _kmeans_subsample(self, k):\n        scores = []\n        for _ in range(self.number_of_subsamples):\n            subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n            kmeans = KMeans(n_clusters=k).fit(subsample)\n            scores.append(kmeans.inertia_)\n        stability = np.std(scores)\n        return stability, k\n\n    def get_optimal_k(self):\n        return self.optimal_k\n\n    def get_stability_summary(self):\n        return self.stability_scores\nEOF\n\ncat <<EOF > test_implementation.py\nimport numpy as np\nfrom stable_kmeans import StableKMeans\nfrom sklearn.datasets import make_blobs\nimport time\n\n# Generate data\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\n\n# Initialize\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\n\n# Run serial\nstart_time = time.time()\nsk.fit_serial(verbose=True)\nserial_time = time.time() - start_time\noptimal_k = sk.get_optimal_k()\n\n# Run parallel\nstart_time = time.time()\nsk.fit_parallel(n_jobs=2, verbose=True)\nparallel_time = time.time() - start_time\nspeedup = serial_time / parallel_time\n\n# Compare performance\nprint(f'Serial time: {serial_time:.4f} seconds')\nprint(f'Parallel time: {parallel_time:.4f} seconds')\nprint(f'Speedup: {speedup:.2f}x')\nprint(f'Optimal k: {optimal_k}')\nEOF\n\npython3 test_implementation.py\n"
"cat <<EOF > stable_kmeans.py\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport multiprocessing\n\nclass StableKMeans:\n    def __init__(self, data, k_max, percent_subsampling=0.7, number_of_subsamples=20):\n        self.data = data\n        self.k_max = k_max\n        self.percent_subsampling = percent_subsampling\n        self.number_of_subsamples = number_of_subsamples\n        self.stability_scores = []\n        self.optimal_k = None\n\n    def fit_serial(self, verbose=True):\n        for k in range(1, self.k_max + 1):\n            scores = []\n            for _ in range(self.number_of_subsamples):\n                subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n                kmeans = KMeans(n_clusters=k).fit(subsample)\n                scores.append(kmeans.inertia_)\n            stability = np.std(scores)\n            self.stability_scores.append(stability)\n            if verbose:\n                print(f'K: {k}, Stability: {stability}')\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n\n    def fit_parallel(self, n_jobs=None, verbose=True):\n        with multiprocessing.Pool(n_jobs) as pool:\n            results = pool.map(self._kmeans_subsample, range(1, self.k_max + 1))\n        self.stability_scores = [result[0] for result in results]\n        self.optimal_k = np.argmin(self.stability_scores) + 1\n        if verbose:\n            for k, stability in enumerate(self.stability_scores, start=1):\n                print(f'K: {k}, Stability: {stability}')\n\n    def _kmeans_subsample(self, k):\n        scores = []\n        for _ in range(self.number_of_subsamples):\n            subsample = self.data[np.random.choice(self.data.shape[0], int(self.percent_subsampling * self.data.shape[0]), replace=False)]\n            kmeans = KMeans(n_clusters=k).fit(subsample)\n            scores.append(kmeans.inertia_)\n        stability = np.std(scores)\n        return stability, k\n\n    def get_optimal_k(self):\n        return self.optimal_k\n\n    def get_stability_summary(self):\n        return self.stability_scores\nEOF\n\ncat <<EOF > test_implementation.py\nimport numpy as np\nfrom stable_kmeans import StableKMeans\nfrom sklearn.datasets import make_blobs\nimport time\n\n# Generate data\ndata, _ = make_blobs(n_samples=500, centers=4, random_state=42)\n\n# Initialize\nsk = StableKMeans(data, k_max=8, number_of_subsamples=15)\n\n# Run serial\nstart_time = time.time()\nsk.fit_serial(verbose=True)\nserial_time = time.time() - start_time\noptimal_k = sk.get_optimal_k()\n\n# Run parallel\nstart_time = time.time()\nsk.fit_parallel(n_jobs=2, verbose=True)\nparallel_time = time.time() - start_time\nspeedup = serial_time / parallel_time\n\n# Compare performance\nprint(f'Serial time: {serial_time:.4f} seconds')\nprint(f'Parallel time: {parallel_time:.4f} seconds')\nprint(f'Speedup: {speedup:.2f}x')\nprint(f'Optimal k: {optimal_k}')\nEOF\n\npython3 test_implementation.py\n"
'python3\n'
['asciinema rec --stdin /logs/tests.cast', 'Enter']
['clear', 'Enter']
['bash ', '/tests/run-tests.sh', 'Enter']
['C-d']
['C-d']
